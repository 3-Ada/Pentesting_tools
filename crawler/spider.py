import requests
import re
from urllib.parse import urljoin
import optparse

def get_arguments():
    parser = optparse.OptionParser()
    parser.add_option('-u', '--url', dest='url', help='Target URL')
    (options, arguments) = parser.parse_args()
    if not options.url:
        parser.error('Please enter target url')
    return options

def request(url):
    try:
        return requests.get('http://' + url, timeout=5)
    except requests.exceptions.ConnectionError or requests.exceptions.Timeout:
        pass

def extract_links_from(url):
    response = requests.get(url)
    return re.findall('(?:href=")(.*?)"', str(response.content))

def crawl(target_url):
    href_links = extract_links_from(target_url)
    target_links = []
    for link in href_links:
        link = urljoin(target_url, link)
        if '#' in link:
            link = link.split('#')[0]
        if target_url in link and link not in target_links:
            target_links.append(link)
            print(link)
            crawl(link)

#target_url = 'http://10.0.2.7/mutillidae/'
options = get_arguments()
target_url = options.url
try:
    if 'http://' not in target_url:
        target_url = 'http://' + target_url
    crawl(target_url)
except KeyboardInterrupt:
    print('Mischief Managed!')
